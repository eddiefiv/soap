{
    "general": {
        "agent_count": 2,
        "worker_count": 3
    },
    "llama_cpp_settings": {
        "70b": {
            "filepath": null,
            "ctx_size": 2048,
            "gpu_layer_count": 41,
            "batch_size": 512
        },
        "13b": {
            "filepath": null,
            "ctx_size": 2048,
            "gpu_layer_count": 21,
            "batch_size": 512
        },
        "7b": {
            "filepath": "openhermes-2.5-mistral-7b.Q5_K_M.gguf",
            "ctx_size": 2048,
            "gpu_layer_count": 33,
            "batch_size": 512
        },
        "hyperparams": {
            "temperature": 0.7,
            "max_tokens": 3000,
            "top_p": 0.92,
            "min_p": 0.05,
            "repeat_penalty": 1.1,
            "presence_penalty": 1.0,
            "top_k": 100,
            "mirostat_eta": 0.1,
            "mirostat_tau": 5
        }
    },
    "discord": {
        "botId": "1195806892023353405"
    },
    "dev": {
        "debug_mode": false
    }
}